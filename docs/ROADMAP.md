# B3Quant - Machine Learning Engineer Portfolio Roadmap

> **Objetivo**: Demonstrar expertise completa em MLOps, modelos avan√ßados, e deployment de sistemas de ML em produ√ß√£o para vagas de Machine Learning Engineer.

---

## üéØ ESTRAT√âGIA REVISADA

Este roadmap foca em construir um **end-to-end ML system** para pricing e trading de op√ß√µes, demonstrando:
- ‚úÖ Feature engineering sofisticado
- ‚úÖ M√∫ltiplos modelos (cl√°ssicos ‚Üí deep learning ‚Üí ensemble)
- ‚úÖ MLOps completo (tracking, registry, serving, monitoring)
- ‚úÖ Compara√ß√£o rigorosa entre modelos
- ‚úÖ Production-ready deployment

---

## FASE 2: CORE ANALYTICS & ML FOUNDATION ‚úÖ COMPLETA
**Status**: 100% COMPLETO | **Released**: v0.1.18 (PyPI)

### 2.1 Feature Engineering Module ‚úÖ COMPLETO
**Tempo Real**: 1 semana | **Prioridade**: ALTA

#### Features B√°sicas ‚úÖ COMPLETO
- [x] Moneyness (S/K, log-moneyness)
- [x] Time to maturity (days, years)
- [x] Greeks (Delta, Gamma, Vega, Theta, Rho)
- [x] Implied Volatility

#### Features Core ‚úÖ COMPLETO (Commit: bd71263)
- [x] **Moneyness Features**
  - [x] moneyness (S/K)
  - [x] log_moneyness
  - [x] is_itm, is_atm, is_otm flags

- [x] **Time Features**
  - [x] day_of_week, day_of_month, month, quarter
  - [x] is_month_end, is_quarter_end
  - [x] sqrt_time, inv_sqrt_time
  - [x] is_short_term, is_medium_term, is_long_term

- [x] **Volatility Surface Features (Basic)**
  - [x] IV rank (10d, 30d, 60d)
  - [x] IV percentile (10d, 30d, 60d)
  - [x] Volatility skew (Put - Call IV)

- [x] **Market Microstructure**
  - [x] Realized volatility (10d, 30d, 60d)
  - [x] Momentum (10d, 30d, 60d)
  - [x] Volume ratio (10d, 30d, 60d)

- [x] **Option Metrics**
  - [x] volume_pct
  - [x] put_call_ratio
  - [x] IV statistics (mean, std, min, max, median, range, cv)

#### Features Avan√ßadas ‚úÖ COMPLETO (Commit: f608940)
- [x] **Greeks Exposure Features**
  - [x] Total gamma exposure by underlying/date
  - [x] Total vega exposure
  - [x] Delta-weighted volume
  - [x] Delta-hedged value
  - [x] Max gamma strike identification

- [x] **Volatility of Volatility**
  - [x] Vol of vol (10d, 30d, 60d rolling)
  - [x] IV skewness by window

- [x] **Advanced Technical Indicators**
  - [x] Bollinger Bands (width, position) - customizable std
  - [x] RSI (Relative Strength Index) - customizable period

- [x] **Market Regime Detection**
  - [x] Regime volatility (20d, 50d, 100d)
  - [x] Trend strength indicators
  - [x] Autocorrelation features
  - [x] Binary regime flags (is_trending, is_ranging, is_volatile)
  - [x] Benchmark correlation (optional IBOV integration)

**Implementa√ß√£o**:
- ‚úÖ `b3quant/features/option_features.py` (273 lines, 13 tests)
- ‚úÖ `b3quant/features/advanced_features.py` (326 lines, 15 tests)
- ‚úÖ `b3quant/features/__init__.py` (exports both classes)

**Referencias**:
- [Machine Learning for Options Trading (2025)](https://www.amazon.com/Machine-Learning-Options-Trading-Comprehensive-ebook/dp/B0FTTG9GVG)
- [Deep Learning for Options Trading (2024)](https://arxiv.org/html/2407.21791v1)

---

### 2.2 Data Pipeline & Storage ‚úÖ COMPLETO
**Tempo Real**: J√° implementado | **Prioridade**: ALTA

- [x] Parquet data lake with partitioning (year/month/day)
- [x] Snappy, gzip, zstd compression support
- [x] Efficient read/write operations (10-20x faster than TXT)
- [x] Automatic caching layer
- [x] Chunked parsing for memory efficiency

**Notas**: Feature store e data validation s√£o necess√°rios apenas no reposit√≥rio ML (b3quant-ml), n√£o na biblioteca core.

---

### 2.3 Baseline Model & Evaluation Framework ‚è≥ PARCIAL
**Tempo**: 3-4 dias | **Prioridade**: M√âDIA

#### Modelos Baseline
- [x] Black-Scholes (j√° implementado com Greeks)
- [x] Implied Volatility solver (Newton-Raphson + Brent)
- [ ] **Heston Model** (volatilidade estoc√°stica) - FASE 3
- [ ] **Gradient Boosted Trees** (XGBoost/LightGBM) - Reposit√≥rio ML

#### Evaluation Framework
**Nota**: M√©tricas e backtesting devem ser implementados no reposit√≥rio ML (b3quant-ml), n√£o na biblioteca.

A biblioteca b3quant fornece:
- ‚úÖ Pricing models (Black-Scholes)
- ‚úÖ Greeks calculation
- ‚úÖ IV solver
- ‚úÖ Feature engineering

O reposit√≥rio b3quant-ml implementar√°:
- ‚è≥ ML models (XGBoost, LSTM, VAE, etc)
- ‚è≥ Evaluation metrics
- ‚è≥ Backtesting framework
- ‚è≥ Model comparison

---

---

## ‚ö†Ô∏è SEPARA√á√ÉO DE RESPONSABILIDADES

**Biblioteca b3quant** (COMPLETA - v0.1.18):
- ‚úÖ Download de dados B3 (COTAHIST)
- ‚úÖ Parser de arquivos
- ‚úÖ Parquet data lake
- ‚úÖ Feature engineering (core + advanced)
- ‚úÖ Black-Scholes pricing + Greeks
- ‚úÖ Implied Volatility solver
- ‚úÖ 179 unit tests
- ‚úÖ Publicada no PyPI

**Reposit√≥rio b3quant-ml** (PR√ìXIMA FASE):
- ‚è≥ ML models (XGBoost, LSTM, VAE, ViT, PINN)
- ‚è≥ MLOps stack (MLflow, Airflow, FastAPI)
- ‚è≥ Evaluation metrics & backtesting
- ‚è≥ Model deployment
- ‚è≥ Monitoring & drift detection
- üìÑ Guia completo: `ML_PROJECT_SETUP.md`

---

## FASE 3: MODELOS AVAN√áADOS DE ML (4-5 semanas) üî• CORE
**Status**: 0% | **Local**: Reposit√≥rio b3quant-ml (separado)

### 3.1 Tree-Based Models (Week 1)
**Prioridade**: ALTA - Benchmark robusto

- [ ] **XGBoost/LightGBM para IV prediction**
  - Hyperparameter tuning (Optuna)
  - Feature importance analysis
  - SHAP values (Explainable AI)

- [ ] **Random Forest para regime classification**
  - Identificar regimes de mercado
  - Feature engineering espec√≠fico

**Por que**:
- Tree models s√£o SOTA para tabular data (segundo pesquisa)
- Mais r√°pidos que DL para treinar
- Interpretabilidade (SHAP)

**Refer√™ncias**:
- [Can Machine Learning Algorithms Outperform Traditional Models for Option Pricing?](https://arxiv.org/html/2510.01446v1)

---

### 3.2 Deep Learning - LSTM/GRU (Week 2)
**Prioridade**: ALTA - Time series modeling

- [ ] **LSTM-GRU Hybrid para IV forecasting**
  - Sequence-to-sequence architecture
  - Attention mechanism
  - Multi-task learning (pre√ßo + IV)

- [ ] **Bidirectional LSTM**
  - Capturar depend√™ncias futuras e passadas

- [ ] **Feature engineering temporal**
  - Sliding windows
  - Multi-horizon prediction

**Por que**:
- Excelente para s√©ries temporais
- Paper de 2025 mostra LSTM accuracy de 94%
- Demonstra conhecimento de arquiteturas recorrentes

**Refer√™ncias**:
- [Option pricing using deep learning approach based on LSTM-GRU](http://aimspress.com/article/doi/10.3934/DSFE.2023016?viewType=HTML)
- [Comparative Analysis of LSTM, GRU, and Transformer Models (2025)](https://dl.acm.org/doi/10.1145/3700058.3700075)

---

### 3.3 Volatility Surface Models (Week 3) üöÄ DIFERENCIAL
**Prioridade**: MUITO ALTA - Estado da arte

- [ ] **Variational Autoencoder (VAE) para IV Surface**
  - Compress volatility surface to latent space
  - Reconstruct surface for interpolation
  - Anomaly detection (mispricing)

- [ ] **Vision Transformer (ViT) para IV Surface**
  - Treat surface as image
  - Superior to CNNs segundo papers de 2025
  - Menos computational cost

- [ ] **Physics-Informed Neural Network (PINN)**
  - Incorporar Black-Scholes PDE como constraint
  - Garantir no-arbitrage conditions
  - ConvTransformer architecture

**Por que**:
- CUTTING EDGE (papers de 2025)
- Demonstra conhecimento de arquiteturas modernas
- Aplica√ß√£o √∫nica de computer vision a finan√ßas

**Refer√™ncias**:
- [Deep Learning Option Pricing with Market Implied Volatility Surfaces (2024)](https://arxiv.org/html/2509.05911v1)
- [Data-Efficient Realized Volatility Forecasting with Vision Transformers (2025)](https://arxiv.org/html/2511.03046)
- [Physics-Informed Convolutional Transformer (2022)](https://arxiv.org/html/2209.10771)
- [Operator Deep Smoothing for Implied Volatility (ICLR 2025)](https://proceedings.iclr.cc/paper_files/paper/2025/hash/f115f619b62833aadc5acb058975b0e6-Abstract-Conference.html)

---

### 3.4 Meta-Learning & Ensemble (Week 4)
**Prioridade**: ALTA - Advanced techniques

- [ ] **Neural Process para IV Surface**
  - Few-shot learning
  - Generate full surface from sparse data
  - Outperforms SABR/SSVI

- [ ] **Ensemble Methods**
  - Stacking: XGBoost + LSTM + VAE
  - Weighted averaging based on market regime
  - Dynamic model selection

**Por que**:
- Meta-learning √© tend√™ncia em 2025
- Ensemble = production best practice
- Demonstra sofistica√ß√£o t√©cnica

**Refer√™ncias**:
- [Meta-Learning Neural Process for IV Surfaces (2024)](https://arxiv.org/html/2509.11928v1)

---

### 3.5 Model Explainability (Week 5)
**Prioridade**: ALTA - Production requirement

- [ ] **SHAP (SHapley Additive exPlanations)**
  - Feature importance global e local
  - Dependency plots
  - Interaction effects

- [ ] **LIME (Local Interpretable Model-agnostic Explanations)**
  - Explain individual predictions

- [ ] **Attention Visualization**
  - Para modelos Transformer/ViT
  - Heatmaps de volatility surface

**Por que**:
- Regulat√≥rio requirement em finan√ßas
- Demonstra profissionalismo
- XAI √© tend√™ncia cr√≠tica em 2025

**Implementa√ß√£o**: `b3quant/explainability/`

---

## FASE 4: MLOps & PRODUCTION (3-4 semanas) üèóÔ∏è ESSENCIAL
**Status**: 0% ‚Üí 100%

### 4.1 Experiment Tracking (Week 1)
**Prioridade**: MUITO ALTA

- [ ] **MLflow Setup**
  - Tracking server (local ‚Üí Docker)
  - Experiment organization
  - Hyperparameter logging
  - Metrics tracking (RMSE, MAE, Sharpe)
  - Model artifacts storage

- [ ] **Weights & Biases** (alternativa/complemento)
  - Superior visualizations
  - Collaborative features
  - Free tier generoso

**Custo**: $0 (local) ou ~$50/m√™s (W&B Team)

**Implementa√ß√£o**:
- `docker-compose.yml` (MLflow + Postgres + MinIO)
- `b3quant/mlops/tracking.py`

---

### 4.2 Model Registry & Versioning (Week 1-2)
**Prioridade**: ALTA

- [ ] **MLflow Model Registry**
  - Model versioning
  - Stage transitions (Staging ‚Üí Production)
  - Model signatures (input/output schema)
  - Model lineage

- [ ] **DVC (Data Version Control)**
  - Dataset versioning
  - Feature store versioning
  - Git-like workflow

**Implementa√ß√£o**:
- `.dvc/` setup
- `b3quant/mlops/registry.py`

---

### 4.3 Model Serving (Week 2)
**Prioridade**: MUITO ALTA

- [ ] **FastAPI REST API**
  - `/predict` endpoint
  - `/batch_predict` endpoint
  - Input validation (Pydantic)
  - Rate limiting
  - Authentication (JWT)

- [ ] **Model loading strategies**
  - Load from MLflow registry
  - Model caching
  - A/B testing support

- [ ] **Containerization**
  - Docker multi-stage build
  - Minimal image size (<500MB)

**Custo**: $0 (local Docker)

**Implementa√ß√£o**:
- `api/main.py`
- `api/models.py`
- `Dockerfile`

**Refer√™ncias**:
- [A Guide to MLOps with Airflow and MLflow](https://medium.com/thefork/a-guide-to-mlops-with-airflow-and-mlflow-e19a82901f88)

---

### 4.4 Orchestration (Week 3)
**Prioridade**: ALTA

- [ ] **Apache Airflow**
  - DAG para data ingestion (daily)
  - DAG para feature engineering
  - DAG para model retraining (weekly)
  - DAG para backtesting

- [ ] **Monitoring & Alerting**
  - Email alerts em failures
  - Slack integration
  - SLA monitoring

**Custo**: $0 (Docker local)

**Implementa√ß√£o**:
- `dags/data_pipeline.py`
- `dags/model_training.py`
- `dags/backtesting.py`

**Refer√™ncias**:
- [Best practices for orchestrating MLOps pipelines with Airflow](https://www.astronomer.io/docs/learn/airflow-mlops)

---

### 4.5 Monitoring & Drift Detection (Week 4)
**Prioridade**: ALTA - Production critical

- [ ] **Model Performance Monitoring**
  - Prediction latency
  - Throughput
  - Error rates

- [ ] **Data Drift Detection**
  - Feature distribution shifts
  - Covariate drift
  - Concept drift

- [ ] **Model Drift Detection**
  - Performance degradation
  - Automatic retraining triggers

- [ ] **Tools**
  - Evidently AI (open source)
  - Prometheus + Grafana
  - Custom dashboards

**Custo**: $0 (open source)

**Implementa√ß√£o**:
- `b3quant/monitoring/drift_detector.py`
- `dashboards/monitoring.json`

**Refer√™ncias**:
- [MLOps: Deploying and Monitoring ML Models in 2025](https://dasroot.net/posts/2025/12/mlops-deploying-monitoring-ml-models-2025/)

---

## FASE 5: CLOUD DEPLOYMENT (2-3 semanas) ‚òÅÔ∏è PORTFOLIO BOOST
**Status**: 0% ‚Üí 100%

### 5.1 Infrastructure as Code (Week 1)
**Prioridade**: M√âDIA-ALTA

- [ ] **Terraform for GCP**
  - Compute Engine (API serving)
  - Cloud Storage (data lake)
  - Cloud SQL (metadata)
  - Cloud Run (serverless API)

- [ ] **Cost optimization**
  - Spot instances
  - Auto-scaling
  - Budget alerts

**Custo**: $0-50/m√™s (GCP free tier: $300 credits)

**Implementa√ß√£o**: `terraform/`

---

### 5.2 CI/CD Pipeline (Week 2)
**Prioridade**: ALTA

- [ ] **GitHub Actions**
  - Unit tests on PR
  - Integration tests
  - Model training on merge to main
  - Auto-deploy to staging
  - Manual approval for prod

- [ ] **Pre-commit hooks**
  - Black formatting
  - Ruff linting
  - Mypy type checking
  - Pytest coverage > 80%

**Custo**: $0 (GitHub Actions free tier)

**Implementa√ß√£o**: `.github/workflows/`

---

### 5.3 Production Deployment (Week 3)
**Prioridade**: M√âDIA

- [ ] **API em Cloud Run**
  - Auto-scaling
  - Load balancing
  - HTTPS

- [ ] **Scheduled jobs em Cloud Scheduler**
  - Daily data ingestion
  - Weekly retraining

- [ ] **Monitoring em Cloud Monitoring**

**Custo**: ~$50-100/m√™s (production-like)

---

## FASE 6: DOCUMENTATION & PORTFOLIO (1-2 semanas) üìö
**Status**: 0% ‚Üí 100%

### 6.1 Technical Documentation
- [ ] **Architecture diagram** (C4 model)
- [ ] **Model cards** para cada modelo
- [ ] **API documentation** (OpenAPI/Swagger)
- [ ] **Runbook** (how to deploy, troubleshoot)

### 6.2 Case Studies & Blog Posts
- [ ] **"Building a Production ML System for Options Pricing"**
  - End-to-end architecture
  - Model comparison results
  - Lessons learned

- [ ] **"Vision Transformers for Volatility Surface Prediction"**
  - Novel application of ViT
  - Technical deep dive

- [ ] **Jupyter notebooks**
  - EDA (Exploratory Data Analysis)
  - Model comparison
  - Backtesting results
  - Visualizations (volatility surface 3D plots)

### 6.3 GitHub README
- [ ] **Badges** (tests, coverage, version, license)
- [ ] **Quick start** (Docker one-liner)
- [ ] **Architecture diagram**
- [ ] **Model performance comparison table**
- [ ] **Live demo** (Streamlit app?)

### 6.4 Portfolio Website/Presentation
- [ ] **Slides** para entrevistas t√©cnicas
- [ ] **Demo video** (2-3 min)
- [ ] **Metrics dashboard** (screenshot ou live)

---

## üéØ TIMELINE TOTAL: 12-15 semanas

| Fase | Dura√ß√£o | Custo | Prioridade |
|------|---------|-------|------------|
| Fase 2 (ML Foundation) | 3-4 semanas | $0 | üî• CR√çTICA |
| Fase 3 (Advanced Models) | 4-5 semanas | $0 | üî• CR√çTICA |
| Fase 4 (MLOps) | 3-4 semanas | $0 | üî• CR√çTICA |
| Fase 5 (Cloud) | 2-3 semanas | $50-100 | ‚ö†Ô∏è M√âDIA |
| Fase 6 (Portfolio) | 1-2 semanas | $0 | ‚úÖ ALTA |

**Custo total**: ~$50-150 (maioria no cloud deployment)

---

## üöÄ DIFERENCIAL COMPETITIVO

Este projeto demonstra:

### 1. **Expertise T√©cnica**
- ‚úÖ State-of-the-art models (VAE, ViT, PINN, Neural Process)
- ‚úÖ Production ML (n√£o s√≥ Jupyter notebooks)
- ‚úÖ MLOps completo (tracking, serving, monitoring)

### 2. **Software Engineering**
- ‚úÖ Clean architecture
- ‚úÖ Type hints + testes (>80% coverage)
- ‚úÖ CI/CD pipeline
- ‚úÖ IaC (Terraform)

### 3. **Domain Knowledge**
- ‚úÖ Finance + Options + Derivatives
- ‚úÖ Quant methods (Black-Scholes, Heston, SABR)
- ‚úÖ Trading strategies & backtesting

### 4. **End-to-End Ownership**
- ‚úÖ Data engineering
- ‚úÖ Feature engineering
- ‚úÖ Model development
- ‚úÖ Deployment
- ‚úÖ Monitoring

---

## üìä SUCCESS METRICS

**Para o Portfolio**:
- [ ] 5+ modelos implementados (BS, Heston, XGBoost, LSTM, VAE)
- [ ] Model comparison com statistical tests
- [ ] API deployed em cloud (mesmo que staging)
- [ ] Monitoring dashboard funcional
- [ ] 3+ blog posts t√©cnicos
- [ ] GitHub repo com >80% test coverage
- [ ] Documenta√ß√£o completa

**Para Entrevistas**:
- Projeto end-to-end de ML em produ√ß√£o
- Decis√µes de trade-off bem documentadas
- Resultados quantitativos (RMSE, Sharpe ratio, etc)
- Live demo funcionando

---

## üéì LEARNING OUTCOMES

Ao final deste projeto, voc√™ ter√° demonstrado:

1. **ML Engineering**
   - Feature engineering avan√ßado
   - Hyperparameter tuning em escala
   - Model selection rigoroso
   - Ensemble methods

2. **Deep Learning**
   - LSTM/GRU para time series
   - VAE para dimensionality reduction
   - Vision Transformers para non-image data
   - Physics-Informed NNs

3. **MLOps**
   - Experiment tracking (MLflow)
   - Model registry & versioning
   - REST API serving (FastAPI)
   - Orchestration (Airflow)
   - Monitoring & drift detection

4. **DevOps**
   - Docker & containerization
   - CI/CD (GitHub Actions)
   - IaC (Terraform)
   - Cloud deployment (GCP)

5. **Communication**
   - Technical writing
   - Data visualization
   - Architecture diagrams
   - Presentation skills

---

## üìö KEY REFERENCES

### Papers (Estado da Arte 2025)
1. [Deep Learning Option Pricing with Market Implied Volatility Surfaces](https://arxiv.org/html/2509.05911v1)
2. [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/html/2511.03046)
3. [Operator Deep Smoothing for Implied Volatility (ICLR 2025)](https://proceedings.iclr.cc/paper_files/paper/2025/hash/f115f619b62833aadc5acb058975b0e6-Abstract-Conference.html)
4. [Meta-Learning Neural Process for IV Surfaces](https://arxiv.org/html/2509.11928v1)
5. [Can ML Algorithms Outperform Traditional Models?](https://arxiv.org/html/2510.01446v1)
6. [Deep Learning for Options Trading: End-to-End](https://arxiv.org/html/2407.21791v1)

### Books
1. [Machine Learning for Options Trading (2025)](https://www.amazon.com/Machine-Learning-Options-Trading-Comprehensive-ebook/dp/B0FTTG9GVG)
2. [Machine Learning for Algorithmic Trading (Stefan Jansen)](https://github.com/stefan-jansen/machine-learning-for-trading)

### MLOps Resources
1. [MLflow Documentation](https://mlflow.org/)
2. [Airflow MLOps Best Practices](https://www.astronomer.io/docs/learn/airflow-mlops)
3. [A Guide to MLOps with Airflow and MLflow](https://medium.com/thefork/a-guide-to-mlops-with-airflow-and-mlflow-e19a82901f88)

---

## ‚ö° QUICK START (After Completion)

```bash
# Clone repo
git clone https://github.com/renves/b3quant.git
cd b3quant

# Start MLOps stack
docker-compose up -d

# Train all models
python scripts/train_all_models.py

# Compare models
python scripts/compare_models.py

# Start API
docker run -p 8000:8000 b3quant-api

# Test prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"S": 100, "K": 105, "T": 0.5, "r": 0.05}'
```

---

## üéØ PR√ìXIMOS PASSOS IMEDIATOS

### ‚úÖ FASE 2 COMPLETADA (2026-01-03)
- [x] Feature engineering core module (option_features.py)
- [x] Feature engineering advanced module (advanced_features.py)
- [x] 28 testes unit√°rios feature engineering (100% passing)
- [x] 179 total unit tests (100% passing)
- [x] README atualizado com documenta√ß√£o completa
- [x] Released v0.1.18 to PyPI
- [x] Closes issue #18

**Commits**:
- `bd71263` - feat: add core feature engineering
- `bb36fed` - feat: add advanced feature engineering module
- `f608940` - docs: add advanced features documentation (Closes #18)

---

### üìç PR√ìXIMO: Criar Reposit√≥rio b3quant-ml

1. **Setup Inicial** (1 dia)
   - Criar novo reposit√≥rio GitHub: `b3quant-ml`
   - Copiar estrutura de `ML_PROJECT_SETUP.md`
   - Setup pyproject.toml com depend√™ncias ML
   - Docker Compose para MLOps stack

2. **Fase 3.1: Tree-Based Models** (Week 1)
   - XGBoost/LightGBM para IV prediction
   - Hyperparameter tuning (Optuna)
   - SHAP explainability
   - Cross-validation temporal

3. **Fase 3.2: LSTM/GRU** (Week 2)
   - Time series forecasting
   - Multi-task learning (price + IV)

4. **Fase 3.3: VAE + ViT** (Week 3-4)
   - Volatility surface modeling
   - State-of-the-art architectures

5. **Fase 4: MLOps** (Week 5-7)
   - MLflow tracking
   - FastAPI serving
   - Airflow orchestration

**Status atual**: Biblioteca b3quant v0.1.18 COMPLETA ‚úÖ | Pr√≥ximo: Criar b3quant-ml üöÄ
