# B3Quant ML - Machine Learning Project Setup

Este documento cont√©m instru√ß√µes completas para criar e configurar o projeto de Machine Learning que usa a biblioteca `b3quant`.

---

## üéØ Objetivo do Projeto

Construir um **end-to-end ML system** para pricing e trading de op√ß√µes da B3, demonstrando expertise em:
- Feature engineering avan√ßado
- Modelos state-of-the-art (XGBoost, LSTM, VAE, ViT, PINN)
- MLOps completo (MLflow, Airflow, FastAPI)
- Production deployment

**Portfolio alvo**: Machine Learning Engineer

---

## üìÅ Estrutura do Projeto

```
b3quant-ml/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .python-version
‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Dados (n√£o versionado)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # COTAHIST files
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # Features engineered
‚îÇ   ‚îî‚îÄ‚îÄ external/                  # Benchmarks (IBOV, etc)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb              # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_baseline_models.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_deep_learning.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 05_model_comparison.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configura√ß√µes centralizadas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                     # Data processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py             # Load data using b3quant
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.py       # Data cleaning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_store.py      # Feature storage & versioning
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/                 # Feature engineering (usa b3quant)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ builder.py            # Wrapper sobre b3quant features
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # ML Models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py               # Base model class
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline/             # Tree-based models
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xgboost_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lightgbm_model.py
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deep_learning/        # Neural networks
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gru_model.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vae_model.py      # Variational Autoencoder
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vit_model.py      # Vision Transformer
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pinn_model.py     # Physics-Informed NN
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ensemble/             # Ensemble methods
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ stacking.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                 # Training utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py            # Training loop
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tuner.py              # Hyperparameter tuning (Optuna)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callbacks.py          # Training callbacks
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/               # Model evaluation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py            # Custom metrics for options
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backtester.py         # Backtesting framework
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ explainer.py          # SHAP, LIME, attention viz
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îî‚îÄ‚îÄ io.py
‚îÇ
‚îú‚îÄ‚îÄ mlops/                        # MLOps infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ mlflow/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mlflow.env
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_pipeline.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_pipeline.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference_pipeline.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ airflow.env
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ main.py               # FastAPI app
‚îÇ       ‚îú‚îÄ‚îÄ models.py             # Pydantic schemas
‚îÇ       ‚îú‚îÄ‚îÄ endpoints/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ health.py
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ experiments/                  # Experimentos trackados
‚îÇ   ‚îú‚îÄ‚îÄ experiment_001_baseline/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_002_lstm/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py
‚îÇ   ‚îî‚îÄ‚îÄ compare_models.py
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ architecture.md
    ‚îú‚îÄ‚îÄ model_cards/              # Model documentation
    ‚îî‚îÄ‚îÄ deployment.md
```

---

## üîß Configura√ß√£o Inicial

### 1. Depend√™ncias (pyproject.toml)

```toml
[project]
name = "b3quant-ml"
version = "0.1.0"
description = "Machine Learning models for B3 options pricing"
requires-python = ">=3.10"

dependencies = [
    # Core
    "b3quant>=0.1.17",
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "scipy>=1.10.0",

    # ML - Tree models
    "xgboost>=2.0.0",
    "lightgbm>=4.0.0",
    "catboost>=1.2.0",

    # ML - Deep Learning
    "torch>=2.0.0",
    "tensorflow>=2.15.0",
    "transformers>=4.30.0",

    # Hyperparameter tuning
    "optuna>=3.5.0",
    "ray[tune]>=2.9.0",

    # Explainability
    "shap>=0.44.0",
    "lime>=0.2.0",

    # MLOps
    "mlflow>=2.10.0",
    "great-expectations>=0.18.0",

    # Visualization
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
    "plotly>=5.18.0",

    # Utilities
    "pydantic>=2.5.0",
    "click>=8.1.0",
    "tqdm>=4.65.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.5.0",
    "jupyter>=1.0.0",
    "ipykernel>=6.25.0",
]

api = [
    "fastapi>=0.108.0",
    "uvicorn[standard]>=0.25.0",
    "pydantic-settings>=2.1.0",
]

airflow = [
    "apache-airflow>=2.8.0",
]

[project.scripts]
train = "src.scripts.train:main"
evaluate = "src.scripts.evaluate:main"
```

### 2. Docker Compose (MLOps Stack)

```yaml
version: '3.8'

services:
  # MLflow Tracking Server
  mlflow:
    build: ./mlops/mlflow
    ports:
      - "5000:5000"
    environment:
      - BACKEND_STORE_URI=postgresql://mlflow:mlflow@postgres:5432/mlflow
      - ARTIFACT_ROOT=s3://mlflow-artifacts
    depends_on:
      - postgres
      - minio
    volumes:
      - ./mlflow-data:/mlflow
    networks:
      - ml-network

  # PostgreSQL (MLflow backend)
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=mlflow
      - POSTGRES_DB=mlflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - ml-network

  # MinIO (S3-compatible artifact storage)
  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - ml-network

  # Airflow (Optional - for production)
  # airflow-webserver:
  #   build: ./mlops/airflow
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     - postgres
  #   environment:
  #     - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  #   networks:
  #     - ml-network

volumes:
  postgres-data:
  minio-data:

networks:
  ml-network:
    driver: bridge
```

### 3. Configura√ß√£o (.env)

```bash
# Data
DATA_DIR=./data
RAW_DATA_DIR=./data/raw
PROCESSED_DATA_DIR=./data/processed

# B3Quant
B3QUANT_CACHE_DIR=./data/raw
B3QUANT_USE_PARQUET=true

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=b3quant-options

# Models
MODEL_DIR=./models
CHECKPOINT_DIR=./checkpoints

# Training
SEED=42
DEVICE=cuda  # or cpu
NUM_WORKERS=4
```

---

## üöÄ Workflow de Desenvolvimento

### Fase 1: Setup & Data Exploration (Semana 1)

```bash
# 1. Clone e setup
git clone <repo-url> b3quant-ml
cd b3quant-ml
uv sync

# 2. Download data
uv run python scripts/download_data.py --year 2024

# 3. Start MLflow
docker-compose up -d mlflow postgres minio

# 4. Jupyter EDA
uv run jupyter notebook notebooks/01_eda.ipynb
```

**Deliverables**:
- Data downloaded (2020-2024)
- EDA notebook com insights
- Data quality report

### Fase 2: Feature Engineering & Baseline (Semana 2-3)

```python
# notebooks/02_feature_engineering.ipynb

from b3quant import get_options, get_stocks
from b3quant.features import OptionFeatureEngineer, AdvancedFeatureEngineer

# Load data
options = get_options(year=2024)
stocks = get_stocks(year=2024)

# Engineer features
fe = OptionFeatureEngineer()
afe = AdvancedFeatureEngineer()

options_ml = fe.add_all_features(options, stocks)
options_ml = afe.add_all_advanced_features(options_ml, stocks)

# Save to feature store
options_ml.to_parquet('data/processed/features_2024.parquet')
```

```python
# src/models/baseline/xgboost_model.py

import xgboost as xgb
import mlflow

with mlflow.start_run(run_name="xgboost_baseline"):
    # Train model
    model = xgb.XGBRegressor(...)
    model.fit(X_train, y_train)

    # Log to MLflow
    mlflow.log_params(model.get_params())
    mlflow.log_metrics({"rmse": rmse, "mae": mae})
    mlflow.xgboost.log_model(model, "model")
```

**Deliverables**:
- Feature engineering pipeline
- XGBoost baseline (RMSE, MAE)
- SHAP explainability

### Fase 3: Deep Learning Models (Semana 4-6)

**Week 4: LSTM/GRU**
```python
# src/models/deep_learning/lstm_model.py

import torch
import torch.nn as nn

class LSTMIVPredictor(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out
```

**Week 5: VAE for Volatility Surface**
```python
# src/models/deep_learning/vae_model.py

class VolatilitySurfaceVAE(nn.Module):
    """Compress IV surface to latent space"""
    def __init__(self, surface_dim, latent_dim):
        # Encoder: surface -> latent
        # Decoder: latent -> surface
        pass
```

**Week 6: Vision Transformer**
```python
# src/models/deep_learning/vit_model.py

from transformers import ViTModel

class VolatilitySurfaceViT:
    """Treat IV surface as image for ViT"""
    pass
```

**Deliverables**:
- 3+ DL models treinados
- Model comparison dashboard
- Attention visualizations

### Fase 4: MLOps & Production (Semana 7-8)

**Airflow DAG**:
```python
# mlops/airflow/dags/training_pipeline.py

from airflow import DAG
from airflow.operators.python import PythonOperator

dag = DAG('model_training', schedule_interval='@weekly')

download_data = PythonOperator(task_id='download', ...)
engineer_features = PythonOperator(task_id='features', ...)
train_model = PythonOperator(task_id='train', ...)
evaluate_model = PythonOperator(task_id='evaluate', ...)

download_data >> engineer_features >> train_model >> evaluate_model
```

**FastAPI**:
```python
# mlops/api/main.py

from fastapi import FastAPI
import mlflow.pyfunc

app = FastAPI()
model = mlflow.pyfunc.load_model("models:/xgboost_iv/production")

@app.post("/predict")
async def predict(request: PredictionRequest):
    features = prepare_features(request)
    prediction = model.predict(features)
    return {"iv": float(prediction[0])}
```

**Deliverables**:
- MLflow tracking completo
- Airflow DAGs funcionando
- FastAPI serving
- Docker deployment

---

## üìä Experimentos & Tracking

### Estrutura de Experimento

```
experiments/
‚îî‚îÄ‚îÄ experiment_001_xgboost_baseline/
    ‚îú‚îÄ‚îÄ README.md                 # Descri√ß√£o do experimento
    ‚îú‚îÄ‚îÄ config.yaml              # Hyperparameters
    ‚îú‚îÄ‚îÄ train.py                 # Script de treino
    ‚îú‚îÄ‚îÄ results/
    ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
    ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
    ‚îÇ   ‚îî‚îÄ‚îÄ shap_summary.png
    ‚îî‚îÄ‚îÄ mlflow_run_id.txt
```

### MLflow Best Practices

```python
import mlflow

# Set experiment
mlflow.set_experiment("iv_prediction")

with mlflow.start_run(run_name="xgboost_v1"):
    # Log params
    mlflow.log_params({
        "max_depth": 10,
        "learning_rate": 0.01,
        "n_estimators": 100
    })

    # Train model
    model.fit(X_train, y_train)

    # Log metrics
    mlflow.log_metrics({
        "train_rmse": train_rmse,
        "val_rmse": val_rmse,
        "test_rmse": test_rmse
    })

    # Log model
    mlflow.sklearn.log_model(model, "model")

    # Log artifacts
    mlflow.log_artifact("plots/feature_importance.png")

    # Log dataset
    mlflow.log_input(
        mlflow.data.from_pandas(X_train),
        context="training"
    )
```

---

## üß™ Testing Strategy

```python
# tests/unit/test_models.py

def test_xgboost_training():
    model = XGBoostIVModel()
    model.fit(X_train, y_train)
    assert model.is_fitted

def test_prediction_shape():
    predictions = model.predict(X_test)
    assert predictions.shape == (len(X_test),)

def test_prediction_range():
    predictions = model.predict(X_test)
    assert (predictions > 0).all()  # IV must be positive
```

---

## üìù Model Cards

Cada modelo deve ter documenta√ß√£o:

```markdown
# Model Card: XGBoost IV Predictor

## Model Details
- **Name**: XGBoost Implied Volatility Predictor v1.0
- **Type**: Gradient Boosted Trees
- **Task**: Regression (IV prediction)
- **Date**: 2025-01-03

## Intended Use
Predict implied volatility for Brazilian options (B3)

## Training Data
- Period: 2020-2024
- Samples: 1.2M option contracts
- Features: 45 (moneyness, Greeks, time series, regime)

## Performance
- Train RMSE: 0.032
- Val RMSE: 0.045
- Test RMSE: 0.048

## Limitations
- Only works for European options
- Requires underlying price data
- Performance degrades for DTE < 7 days

## Ethical Considerations
For educational/research purposes only.
```

---

## üéØ Success Metrics

### Model Performance
- [ ] Baseline RMSE < 0.05
- [ ] LSTM beats baseline by >10%
- [ ] Ensemble RMSE < 0.04

### MLOps
- [ ] All experiments tracked in MLflow
- [ ] API latency < 100ms
- [ ] Monitoring dashboard deployed

### Portfolio
- [ ] 5+ models implemented
- [ ] Complete documentation
- [ ] Live demo available

---

## üìö References

**Papers**:
1. [Deep Learning Option Pricing (2024)](https://arxiv.org/html/2509.05911v1)
2. [Vision Transformers for Volatility (2025)](https://arxiv.org/html/2511.03046)
3. [Physics-Informed Neural Networks](https://arxiv.org/html/2209.10771)

**Books**:
1. Machine Learning for Options Trading (2025)
2. Hands-On Machine Learning (G√©ron)

**MLOps**:
1. [MLflow Documentation](https://mlflow.org/)
2. [Airflow MLOps Guide](https://www.astronomer.io/docs/learn/airflow-mlops)

---

## üöß Next Steps

1. **Criar reposit√≥rio**: `b3quant-ml`
2. **Setup inicial**: pyproject.toml, docker-compose.yml
3. **Download dados**: 2020-2024
4. **EDA notebook**: An√°lise explorat√≥ria
5. **Baseline model**: XGBoost
6. **MLflow tracking**: Experimentos

**Pronto para come√ßar!** üöÄ
